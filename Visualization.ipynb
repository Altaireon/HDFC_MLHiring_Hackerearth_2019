{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from ast import literal_eval\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_value = -1\n",
    "categorical_limit = 8\n",
    "log_limit = 10000\n",
    "missing_threshold = 99\n",
    "data_path = './DataSet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f'{data_path}Train.csv')\n",
    "test = pd.read_csv(f'{data_path}Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.drop_duplicates(inplace=True)\n",
    "target = train.Col2\n",
    "train.drop(['Col2'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processCol1(train,test):\n",
    "    def splitVal(val):\n",
    "        p1=[]\n",
    "        p2=[]\n",
    "        p3=[]\n",
    "        for x in val:\n",
    "            p1.append(x[:2])\n",
    "            p2.append(x[2:4])\n",
    "            p3.append(x[4:])\n",
    "        return p1,p2,p3\n",
    "\n",
    "    x,y,z = splitVal(train['Col1'])\n",
    "    train['Col1_1'] = x\n",
    "    train['Col1_2'] = y\n",
    "    train['Col1_3'] = z\n",
    "    x,y,z = splitVal(test['Col1'])\n",
    "    test['Col1_1'] = x\n",
    "    test['Col1_2'] = y\n",
    "    test['Col1_3'] = z\n",
    "    train.Col1_1.value_counts()\n",
    "\n",
    "    test.Col1_1.value_counts()\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    l = train.Col1_1.values.tolist()\n",
    "    l.extend(test.Col1_1.values.tolist())\n",
    "    l = np.reshape(np.array(l),(len(l),))\n",
    "    le.fit(l)\n",
    "    train.Col1_1 = le.transform(train.Col1_1)\n",
    "    test.Col1_1 = le.transform(test.Col1_1)\n",
    "\n",
    "    train.Col1_2.value_counts()\n",
    "\n",
    "    test.Col1_2.value_counts()\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    l = train.Col1_2.values.tolist()\n",
    "    l.extend(test.Col1_2.values.tolist())\n",
    "    l = np.reshape(np.array(l),(len(l),))\n",
    "    le.fit(l)\n",
    "    train.Col1_2 = le.transform(train.Col1_2)\n",
    "    test.Col1_2 = le.transform(test.Col1_2)\n",
    "\n",
    "    train.Col1_3.value_counts()\n",
    "\n",
    "    test.Col1_3.value_counts()\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    l = train.Col1_3.values.tolist()\n",
    "    l.extend(test.Col1_3.values.tolist())\n",
    "    l = np.reshape(np.array(l),(len(l),))\n",
    "    le.fit(l)\n",
    "    train.Col1_3 = le.transform(train.Col1_3)\n",
    "    test.Col1_3 = le.transform(test.Col1_3)\n",
    "    train.drop(['Col1'],axis=1,inplace=True)\n",
    "    test.drop(['Col1'],axis=1,inplace=True)\n",
    "    print(train.Col1_1.nunique())\n",
    "    print(train.Col1_2.nunique())\n",
    "    print(train.Col1_3.nunique())\n",
    "    print(test.Col1_1.nunique())\n",
    "    print(test.Col1_2.nunique())\n",
    "    print(test.Col1_3.nunique())\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = processCol1(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=target.value_counts().index,y=target.value_counts().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_table(train,test,drop,threshold):\n",
    "    mis_val = train.isnull().sum()\n",
    "    mis_val_percent = 100 * train.isnull().sum() / len(train)\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(\n",
    "    columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "    '% of Total Values', ascending=False).round(1)\n",
    "    print (\"Your selected dataframe has \" + str(train.shape[1]) + \" columns.\\n\"      \n",
    "        \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "          \" columns that have missing values.\")\n",
    "    if drop: \n",
    "        to_drop = (mis_val_table_ren_columns[mis_val_table_ren_columns[\"% of Total Values\"]>=threshold].index)\n",
    "        print(to_drop)\n",
    "        train.drop(to_drop,axis=1,inplace=True)\n",
    "        test.drop(to_drop,axis=1,inplace=True)\n",
    "    return mis_val_table_ren_columns,train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_values,train,test = missing_values_table(train,test,True,missing_threshold)\n",
    "missing_values.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_dashes(train,test):\n",
    "    for col in train.columns:\n",
    "        if train[col].dtype == object:\n",
    "            train[col] = pd.to_numeric(train[col],errors='coerce')\n",
    "    for col in test.columns:\n",
    "        if test[col].dtype == object:\n",
    "            test[col] = pd.to_numeric(test[col],errors='coerce')\n",
    "    return train,test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = handle_dashes(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchTypes(train, test):\n",
    "    for col in train.columns:\n",
    "        if train[col].dtype == float:\n",
    "            test[col] = test[col].astype('float')\n",
    "        if train[col].dtype == int:\n",
    "            try:\n",
    "                test[col] = test[col].astype('int')\n",
    "            except:\n",
    "                train[col] = train[col].astype('float')\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = matchTypes(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cols = train.columns[train.dtypes=='int']\n",
    "float_cols = train.columns[train.dtypes=='float']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array_equal(A,B)  # test if same shape, same elements values\n",
    "# np.array_equiv(A,B)  # test if broadcastable shape, same elements values\n",
    "# np.allclose(A,B,...) \n",
    "def processDuplicateColumns(train,test,columns,threshold):\n",
    "    data_dict = {}\n",
    "    for toProcessCols in columns:\n",
    "        processedColumns = set()\n",
    "        for mainCol in tqdm(toProcessCols):\n",
    "            if mainCol not in processedColumns:\n",
    "                arr = []\n",
    "                for col in toProcessCols:\n",
    "                    if col != mainCol and col not in processedColumns and np.allclose(train[mainCol],train[col],equal_nan=True) and np.allclose(test[mainCol],test[col],equal_nan=True):\n",
    "                        arr.append(col)\n",
    "                        processedColumns.add(col)\n",
    "                if len(arr) > 0:\n",
    "                    data_dict[mainCol] = arr\n",
    "            processedColumns.add(mainCol)\n",
    "    with open(f'{data_path}duplicate_columns.txt','w') as f:\n",
    "        f.write(str(data_dict))\n",
    "        f.close()\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f'{data_path}duplicate_columns.txt'):\n",
    "    with open(f'{data_path}duplicate_columns.txt','r') as f:\n",
    "        data = literal_eval(f.read())\n",
    "else:\n",
    "    data = processDuplicateColumns(train,test,[int_cols,float_cols],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in tqdm(data.values()):\n",
    "    train.drop(v,axis=1,inplace=True)\n",
    "    test.drop(v,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = train.columns[((train.dtypes == 'int')&(train.nunique() < categorical_limit))]\n",
    "for col in tqdm(categorical_columns):\n",
    "    train[col] = train[col].astype('category')\n",
    "    test[col] = test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_log = train.columns[((train.dtypes != 'category') & (train.max() >= log_limit))]\n",
    "def getSign(val):\n",
    "    if val < 0.0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "for col in col_to_log:\n",
    "    if train[col].isna().sum() == 0 and test[col].isna().sum() == 0:\n",
    "        sign = train[col].apply(getSign)\n",
    "        train[col] = np.log1p(np.abs(train[col]))*sign\n",
    "        sign = test[col].apply(getSign)\n",
    "        test[col] = np.log1p(np.abs(test[col]))*sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlations = train.corr(target).sort_values()\n",
    "# print('Most Positive Correlations:\\n', correlations.tail(15))\n",
    "# print('\\nMost Negative Correlations:\\n', correlations.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = train.copy()\n",
    "cp2 = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = cp[cp.columns[cp.dtypes == 'category']]\n",
    "test = cp2[cp.columns[cp.dtypes == 'category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm_imp = np.loadtxt(f'{data_path}lgbm_imp_final.txt',dtype='str')\n",
    "# lgbm_imp_int = np.loadtxt(f'{data_path}lgbm_imp_int2.txt',dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = cp[np.concatenate((lgbm_imp,lgbm_imp_int))]\n",
    "# test = cp2[np.concatenate((lgbm_imp,lgbm_imp_int))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = cp[lgbm_imp]\n",
    "# test = cp2[lgbm_imp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = cp.copy()\n",
    "# test = cp2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[train.columns[train.dtypes != 'category']].fillna(nan_value,inplace=True)\n",
    "# train[test.columns[train.dtypes != 'category']].fillna(nan_value,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cat\n",
    "# import sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_lgb = lgb.LGBMClassifier()\n",
    "# model_xgb = xgb.XGBClassifier()\n",
    "model_cat = cat.CatBoostClassifier(learning_rate=0.1,iterations=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(3,random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_idx,test_idx in kfold.split(train,target):\n",
    "    x_train,y_train = train.iloc[train_idx],target.iloc[train_idx]\n",
    "    x_test,y_test = train.iloc[test_idx],target.iloc[test_idx]\n",
    "#     model_lgb.fit(x_train,y_train,eval_metric=accuracy_score)\n",
    "#     model_xgb.fit(x_train,y_train,eval_metric=accuracy_score)\n",
    "    model_cat.fit(x_train,y_train,verbose=True)\n",
    "    pred = np.argmax(model_cat.predict_proba(x_test),axis=1)#+model_xgb.predict_proba(x_test)+model_cat.predict_proba(x_test),axis=1)\n",
    "    print(accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(f'{data_path}Sample_submission.csv')\n",
    "# pred = np.argmax(model_lgb.predict_proba(test)+model_xgb.predict_proba(test)+model_cat.predict_proba(test),axis=1)\n",
    "pred = np.argmax(model_cat.predict_proba(test),axis=1)\n",
    "sub.Col2 = pred\n",
    "sub.to_csv('output1.csv',index=False)\n",
    "len(pred[pred==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_csv('Train2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f'{data_path}cat_imp_category.txt',train.columns[model_cat.feature_importances_ > 0].values,fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train.columns[model.feature_importances_ > 20].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(lgbm_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.columns[model.feature_importances_ == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l5 = train.columns[model.feature_importances_ < 5]\n",
    "# g5 = train.columns[model.feature_importances_ >= 5]\n",
    "# l10 = train.columns[(model.feature_importances_ < 10)&(model.feature_importances_ > 10)]\n",
    "# g10 = train.columns[(model.feature_importances_ < 10)&(model.feature_importances_ > 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.Col1_2.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train.columns[model_cat.feature_importances_ == 0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cat.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
