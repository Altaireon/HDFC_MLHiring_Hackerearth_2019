{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import glob\n",
    "import requests\n",
    "from ast import literal_eval\n",
    "from multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './DataSet/'\n",
    "random_state = 42\n",
    "limit = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f'{data_path}Train.csv')\n",
    "test = pd.read_csv(f'{data_path}Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sub = {'Col1':test.Col1,'Col2':np.zeros((test.shape[0],))}\n",
    "pd.DataFrame(dict_sub).to_csv(f'{data_path}Sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sub = {'Col1':train.nunique(axis=1),'Col2':train.Col2}\n",
    "pd.DataFrame(dict_sub).to_csv(f'{data_path}unique_target.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Col2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train.Col1.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.Col2 == 1].to_csv(f'{data_path}only1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = [str(x) for x in train.iloc[17450].values]\n",
    "# with open(f'{data_path}example.txt','w') as f:\n",
    "#     for x in s:\n",
    "#         f.write(x+'\\n')\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitVal(val):\n",
    "    p1=[]\n",
    "    p2=[]\n",
    "    p3=[]\n",
    "    for x in val:\n",
    "        p1.append(x[:2])\n",
    "        p2.append(x[2:4])\n",
    "        p3.append(x[4:])\n",
    "    return p1,p2,p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z = splitVal(train['Col1'])\n",
    "train['Col1_1'] = x\n",
    "train['Col1_2'] = y\n",
    "train['Col1_3'] = z\n",
    "x,y,z = splitVal(test['Col1'])\n",
    "test['Col1_1'] = x\n",
    "test['Col1_2'] = y\n",
    "test['Col1_3'] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Col1_3.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(['Col1'],axis=1,inplace=True)\n",
    "train.drop(['Col1'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape[0]-train.drop_duplicates().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape[0]-test.drop_duplicates().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train.Col2\n",
    "train.drop(['Col2'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train.columns[train.isna().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDuplicateColumns(df,x,cols):\n",
    "    '''\n",
    "    Get a list of duplicate columns.\n",
    "    It will iterate over all the columns in dataframe and find the columns whose contents are duplicate.\n",
    "    :param df: Dataframe object\n",
    "    :return: List of columns whose contents are duplicates.\n",
    "    '''\n",
    "    duplicateColumnNames = []\n",
    "    col = df[x]\n",
    "    for y in cols:\n",
    "        # Select column at yth index.\n",
    "        otherCol = df[y]\n",
    "        # Check if two columns at x 7 y index are equal\n",
    "        if col.equals(otherCol):\n",
    "            duplicateColumnNames.append(y)\n",
    "\n",
    "    return duplicateColumnNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = train.isna().sum()[(train.isna().sum() > int(.99*train.shape[0]))].index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns[train.dtypes == object]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Col836.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Col836.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop.append('Col836')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Col747.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Col747.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop.append('Col747')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Col1_1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Col1_1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "l = train.Col1_1.values.tolist()\n",
    "l.extend(test.Col1_1.values.tolist())\n",
    "l = np.reshape(np.array(l),(len(l),))\n",
    "le.fit(l)\n",
    "train.Col1_1 = le.transform(train.Col1_1)\n",
    "test.Col1_1 = le.transform(test.Col1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Col1_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Col1_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "l = train.Col1_2.values.tolist()\n",
    "l.extend(test.Col1_2.values.tolist())\n",
    "l = np.reshape(np.array(l),(len(l),))\n",
    "le.fit(l)\n",
    "train.Col1_2 = le.transform(train.Col1_2)\n",
    "test.Col1_2 = le.transform(test.Col1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Col1_3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Col1_3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "l = train.Col1_3.values.tolist()\n",
    "l.extend(test.Col1_3.values.tolist())\n",
    "l = np.reshape(np.array(l),(len(l),))\n",
    "le.fit(l)\n",
    "train.Col1_3 = le.transform(train.Col1_3)\n",
    "test.Col1_3 = le.transform(test.Col1_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns[test.dtypes == object]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Col702.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Col702.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop.append('Col702')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Col791.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Col791.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop.append('Col791')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Col813.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Col813.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop.append('Col813')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Col813.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Col813.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop.append('Col822')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_cols = ['Col733', 'Col742', 'Col754', 'Col763','Col831', 'Col843', 'Col852']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_strings(val):\n",
    "    if type(val) == str:\n",
    "        try:\n",
    "            x = float(val)\n",
    "            return float(val)\n",
    "        except:\n",
    "            return 0.0\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in str_cols:\n",
    "    train[col] = train[col].apply(processing_strings)\n",
    "    test[col] = test[col].apply(processing_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(to_drop,axis=1,inplace=True)\n",
    "test.drop(to_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('row.txt',np.array(test.iloc[20426].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_unique = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "un=train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in un.index:\n",
    "    if un[k] in dict_unique:\n",
    "        dict_unique[un[k]].append(k)\n",
    "    else:\n",
    "        dict_unique[un[k]] = [k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = train.columns[(train.nunique() < 8)].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(dict_un):\n",
    "    dict_data = dict()\n",
    "    for k in dict_un.keys():\n",
    "        cols=dict_un[k]\n",
    "        for col in cols:\n",
    "            dict_data[col] = getDuplicateColumns(train2,col,cols)\n",
    "    with open(f'{data_path}duplicate_columns.txt','w') as f:\n",
    "        f.write(str(dict_data))\n",
    "        f.close()\n",
    "    return dict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process(cols):\n",
    "#     dict_data = dict()\n",
    "#     for col in cols:\n",
    "#         dict_data[col] = getDuplicateColumns(train,col,cols)\n",
    "#     with open(f'{data_path}duplicate_columns.txt','w') as f:\n",
    "#         f.write(str(dict_data))\n",
    "#         f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f'{data_path}duplicate_columns.txt'):\n",
    "    with open(f'{data_path}duplicate_columns.txt','r') as f:\n",
    "        data = literal_eval(f.read())\n",
    "else:\n",
    "    data = process(dict_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = set()\n",
    "for k,v in data.items():\n",
    "    if len(v) > 1 and k not in items:\n",
    "        items.update(v)\n",
    "        val = train[k].values\n",
    "        train.drop(v,axis=1,inplace=True)\n",
    "        train[k]=val\n",
    "        val = test[k].values\n",
    "        test.drop(v,axis=1,inplace=True)\n",
    "        test[k]=val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_log = train.columns[((train.max(axis=0) >= 8))].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(-1,inplace=True)\n",
    "test.fillna(-1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSign(val):\n",
    "    if val < 0.0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "for col in cols_to_log:\n",
    "    sign = train[col].apply(getSign)\n",
    "    train[col] = np.log1p(np.abs(train[col]))*sign\n",
    "    sign = test[col].apply(getSign)\n",
    "    test[col] = np.log1p(np.abs(test[col]))#*sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in train.columns:\n",
    "#     if train[col].dtype == float:\n",
    "#         train[col] = train[col].astype('int64')\n",
    "# for col in test.columns:\n",
    "#     if test[col].dtype == float:\n",
    "#         test[col] = test[col].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(-1,inplace=True)\n",
    "test.fillna(-1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_to_float = []\n",
    "# for col in train.columns:\n",
    "#     if col!= 'Col2' and train[col].dtype != test[col].dtype:\n",
    "#         col_to_float.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in col_to_float:\n",
    "#     train[col] = train[col].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['Col_NANC'] = train.isna().sum(axis=1)\n",
    "# test['Col_NANC'] = test.isna().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['mean'] = train[train_cols].mean(axis=1)\n",
    "# test['mean'] = test[train_cols].mean(axis=1)\n",
    "\n",
    "# train['max'] = train[train_cols].max(axis=1)\n",
    "# test['max'] = test[train_cols].max(axis=1)\n",
    "\n",
    "# train['min'] = train[train_cols].min(axis=1)\n",
    "# test['min'] = test[train_cols].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Col2'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(f'{data_path}Processed_Train.csv',index=False)\n",
    "test.to_csv(f'{data_path}Processed_Test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_remove_cols = []\n",
    "# for col in train.columns:\n",
    "#     if train[col].dtype != test[col].dtype:\n",
    "#         to_remove_cols.append(col)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
